{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gxwq9Xs1n1MH"
      },
      "outputs": [],
      "source": [
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgdVDcZPiqbl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from typing import Tuple, Optional\n",
        "import math\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1Z72qRylPL4"
      },
      "outputs": [],
      "source": [
        "class ModelArgs:\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        n_layers: int,\n",
        "        head_dim: int,\n",
        "        hidden_dim: int,\n",
        "        n_heads: int,\n",
        "        n_kv_heads: int,\n",
        "        norm_eps: float,\n",
        "        vocab_size: int,\n",
        "        rope_theta: float = 10000,\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.n_layers = n_layers\n",
        "        self.head_dim = head_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.n_kv_heads = n_kv_heads\n",
        "        self.norm_eps = norm_eps\n",
        "        self.vocab_size = vocab_size\n",
        "        self.rope_theta = rope_theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlDvZUXuiqWM"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dims: int, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(dims))\n",
        "        self.eps = eps\n",
        "\n",
        "    def _norm(self, x):\n",
        "        return x * (x.square().mean(-1, keepdim=True) + self.eps).rsqrt()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self._norm(x.float()).type(x.dtype)\n",
        "        return self.weight * output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLYU7q2hk_3P"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, args: \"ModelArgs\"):\n",
        "        super().__init__()\n",
        "\n",
        "        self.w1 = nn.Linear(args.dim, args.hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(args.hidden_dim, args.dim, bias=False)\n",
        "        self.w3 = nn.Linear(args.dim, args.hidden_dim, bias=False)\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "        return self.w2(F.silu(self.w1(x)) * self.w3(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtXP4a5siqQJ"
      },
      "outputs": [],
      "source": [
        "class RoPE(nn.Module):\n",
        "    def __init__(self, dim: int, traditional: bool = False, base: float = 10000.0):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.traditional = traditional\n",
        "        self.base = base\n",
        "        self.freqs = self.create_freqs(dim // 2)\n",
        "\n",
        "    def create_freqs(self, n: int):\n",
        "        freqs = 1.0 / (self.base ** (torch.arange(0, n, 2) / n))\n",
        "        return freqs\n",
        "\n",
        "    def forward(self, x: torch.Tensor, offset: int = 0):\n",
        "        if self.traditional:\n",
        "            t = torch.arange(x.shape[2], device=x.device) + offset\n",
        "        else:\n",
        "            t = torch.arange(x.shape[2], device=x.device)\n",
        "        freqs = self.freqs.to(x.device)\n",
        "        t_sin = torch.sin(t[:, None] * freqs[None, :])\n",
        "        t_cos = torch.cos(t[:, None] * freqs[None, :])\n",
        "        return torch.stack([x[..., 0::2] * t_cos + x[..., 1::2] * t_sin,\n",
        "                           x[..., 0::2] * t_sin - x[..., 1::2] * t_cos], dim=-1).flatten(-2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJwtvbE_iqTM"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, args: \"ModelArgs\"):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "\n",
        "        self.n_heads: int = args.n_heads\n",
        "        self.n_kv_heads: int = args.n_kv_heads\n",
        "\n",
        "        self.repeats = self.n_heads // self.n_kv_heads\n",
        "\n",
        "        self.scale = self.args.head_dim**-0.5\n",
        "\n",
        "        self.wq = nn.Linear(args.dim, args.n_heads * args.head_dim, bias=False)\n",
        "        self.wk = nn.Linear(args.dim, args.n_kv_heads * args.head_dim, bias=False)\n",
        "        self.wv = nn.Linear(args.dim, args.n_kv_heads * args.head_dim, bias=False)\n",
        "        self.wo = nn.Linear(args.n_heads * args.head_dim, args.dim, bias=False)\n",
        "        self.rope = RoPE(args.head_dim, traditional=True)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        cache: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        B, L, D = x.shape\n",
        "\n",
        "        queries, keys, values = self.wq(x), self.wk(x), self.wv(x)\n",
        "\n",
        "        # Prepare the queries, keys and values for the attention computation\n",
        "        queries = queries.view(B, L, self.n_heads, -1).transpose(1, 2)\n",
        "        keys = keys.view(B, L, self.n_kv_heads, -1).transpose(1, 2)\n",
        "        values = values.view(B, L, self.n_kv_heads, -1).transpose(1, 2)\n",
        "\n",
        "        def repeat(a):\n",
        "            a = torch.cat([a.unsqueeze(2)] * self.repeats, dim=2)\n",
        "            return a.view([B, self.n_heads, L, -1])\n",
        "\n",
        "        keys, values = map(repeat, (keys, values))\n",
        "\n",
        "        # Rolling BufferÂ Cache\n",
        "        if cache is not None:\n",
        "            key_cache, value_cache = cache\n",
        "            queries = self.rope(queries, offset=key_cache.shape[2])\n",
        "            keys = self.rope(keys, offset=key_cache.shape[2])\n",
        "            keys = torch.cat([key_cache, keys], dim=2)\n",
        "            values = torch.cat([value_cache, values], dim=2)\n",
        "        else:\n",
        "            queries = self.rope(queries)\n",
        "            keys = self.rope(keys)\n",
        "\n",
        "        scores = (queries * self.scale) @ keys.transpose(-1, -2)\n",
        "        if mask is not None:\n",
        "            scores += mask\n",
        "        scores = F.softmax(scores.float(), dim=-1).type(scores.dtype)\n",
        "        output = (scores @ values).transpose(1, 2).contiguous().view(B, L, -1)\n",
        "        return self.wo(output), (keys, values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK0KDqyWlEO-"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, args: \"ModelArgs\"):\n",
        "        super().__init__()\n",
        "        self.n_heads = args.n_heads\n",
        "        self.dim = args.dim\n",
        "        self.attention = Attention(args)\n",
        "        self.feed_forward = FeedForward(args=args)\n",
        "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "        self.args = args\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        cache: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "    ) -> torch.Tensor:\n",
        "        r, cache = self.attention(self.attention_norm(x), mask, cache)\n",
        "        h = x + r\n",
        "        r = self.feed_forward(self.ffn_norm(h))\n",
        "        out = h + r\n",
        "        return out, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgXGxa0ulHgD"
      },
      "outputs": [],
      "source": [
        "class Mistral(nn.Module):\n",
        "    def __init__(self, args: \"ModelArgs\"):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.vocab_size = args.vocab_size\n",
        "        self.n_layers = args.n_layers\n",
        "        assert self.vocab_size > 0\n",
        "        self.tok_embeddings = nn.Embedding(args.vocab_size, args.dim)\n",
        "        self.layers = nn.ModuleList([TransformerBlock(args=args) for _ in range(args.n_layers)])\n",
        "        self.norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
        "        self.output = nn.Linear(args.dim, args.vocab_size, bias=False)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.xavier_uniform_(module.weight)\n",
        "        elif isinstance(module, RMSNorm):\n",
        "            nn.init.ones_(module.weight)\n",
        "        elif isinstance(module, nn.MultiheadAttention):\n",
        "            nn.init.xavier_uniform_(module.in_proj_weight)\n",
        "            if module.in_proj_bias is not None:\n",
        "                nn.init.zeros_(module.in_proj_bias)\n",
        "            nn.init.xavier_uniform_(module.out_proj.weight)\n",
        "            if module.out_proj.bias is not None:\n",
        "                nn.init.zeros_(module.out_proj.bias)\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "        return mask\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        inputs: torch.Tensor,\n",
        "        cache=None,\n",
        "    ):\n",
        "        h = self.tok_embeddings(inputs)\n",
        "\n",
        "        mask = None\n",
        "        if h.shape[1] > 1:\n",
        "            mask = self._generate_square_subsequent_mask(h.shape[1]).to(h.device)\n",
        "\n",
        "        if cache is None:\n",
        "            cache = [None] * len(self.layers)\n",
        "\n",
        "        for e, layer in enumerate(self.layers):\n",
        "            h, cache[e] = layer(h, mask, cache[e])\n",
        "\n",
        "        return self.output(self.norm(h)), cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i15QmNTr3Ow"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "{\n",
        "  \"architectures\": [\n",
        "    \"MistralForCausalLM\"\n",
        "  ],\n",
        "  \"bos_token_id\": 1,\n",
        "  \"eos_token_id\": 2,\n",
        "  \"hidden_act\": \"silu\",\n",
        "  \"hidden_size\": 4096,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 14336,\n",
        "  \"max_position_embeddings\": 32768,\n",
        "  \"model_type\": \"mistral\",\n",
        "  \"num_attention_heads\": 32,\n",
        "  \"num_hidden_layers\": 32,\n",
        "  \"num_key_value_heads\": 8,\n",
        "  \"rms_norm_eps\": 1e-05,\n",
        "  \"rope_theta\": 10000.0,\n",
        "  \"sliding_window\": 4096,\n",
        "  \"tie_word_embeddings\": false,\n",
        "  \"torch_dtype\": \"bfloat16\",\n",
        "  \"transformers_version\": \"4.34.0.dev0\",\n",
        "  \"use_cache\": true,\n",
        "  \"vocab_size\": 32000\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnTe4zPWiqNA"
      },
      "outputs": [],
      "source": [
        "# Define model hyperparameters\n",
        "model_args = ModelArgs(\n",
        "    dim=4096,            # Embedding dimension\n",
        "    n_layers=4,        # Number of Transformer layers\n",
        "    head_dim=128,         # Head dimension for multi-head attention\n",
        "    hidden_dim=14336,    # Dimension of hidden layer in the feedforward network\n",
        "    n_heads=32,          # Number of attention heads\n",
        "    n_kv_heads=32,       # Number of key/value heads (can be different from n_heads)\n",
        "    norm_eps=1e-5,      # Epsilon value for normalization\n",
        "    vocab_size=32000,   # Size of your vocabulary\n",
        "    rope_theta=10000,   # Base value for Rotary Position Embeddings\n",
        ")\n",
        "\n",
        "# Create the Mistral model\n",
        "model = Mistral(model_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heJeUa1lljhr"
      },
      "source": [
        "![1_PoLsmCzH_dquv8DVnYbkoQ.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_r6Mgl5lhCh",
        "outputId": "566d1d1a-86ac-467e-f2e4-d9f49b4167ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Mistral(\n",
              "  (tok_embeddings): Embedding(50257, 768)\n",
              "  (layers): ModuleList(\n",
              "    (0-11): 12 x TransformerBlock(\n",
              "      (attention): Attention(\n",
              "        (wq): Linear(in_features=768, out_features=16, bias=False)\n",
              "        (wk): Linear(in_features=768, out_features=16, bias=False)\n",
              "        (wv): Linear(in_features=768, out_features=16, bias=False)\n",
              "        (wo): Linear(in_features=16, out_features=768, bias=False)\n",
              "        (rope): RoPE()\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (w1): Linear(in_features=768, out_features=3072, bias=False)\n",
              "        (w2): Linear(in_features=3072, out_features=768, bias=False)\n",
              "        (w3): Linear(in_features=768, out_features=3072, bias=False)\n",
              "      )\n",
              "      (attention_norm): RMSNorm()\n",
              "      (ffn_norm): RMSNorm()\n",
              "    )\n",
              "  )\n",
              "  (norm): RMSNorm()\n",
              "  (output): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7RvMtnSng9J"
      },
      "outputs": [],
      "source": [
        "# Function to get training data\n",
        "def get_training_corpus():\n",
        "    dataset = load_dataset(\"text\", data_files={\"train\": \"/content/cleaned_data.txt\"})\n",
        "    for i in range(0, len(dataset[\"train\"]), 1000):\n",
        "        yield dataset[\"train\"][i : i + 1000][\"text\"]\n",
        "\n",
        "\n",
        "# Load the base tokenizer\n",
        "base_tokenizer = AutoTokenizer.from_pretrained(\"unsloth/mistral-7b-v0.3-bnb-4bit\")\n",
        "\n",
        "# Train the new tokenizer\n",
        "new_tokenizer = base_tokenizer.train_new_from_iterator(get_training_corpus(), vocab_size=1000)\n",
        "\n",
        "# Save the new tokenizer\n",
        "new_tokenizer.save_pretrained(\"new_tokenizer\")\n",
        "\n",
        "# Test the new tokenizer\n",
        "test_text = \"The First day\"\n",
        "encoded = new_tokenizer.encode(test_text)\n",
        "decoded = new_tokenizer.decode(encoded)\n",
        "\n",
        "print(f\"Encoded: {encoded}\")\n",
        "print(f\"Decoded: {decoded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mydwPt-RoVIN"
      },
      "outputs": [],
      "source": [
        "# Add padding token if it doesn't exist\n",
        "if new_tokenizer.pad_token is None:\n",
        "    new_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Ensure pad_token_id is valid\n",
        "if new_tokenizer.pad_token_id is None or new_tokenizer.pad_token_id >= new_tokenizer.vocab_size:\n",
        "    new_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "    new_tokenizer.pad_token_id = new_tokenizer.vocab_size - 1  # Use the last valid token ID as padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "666jWVTOxhyX"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C40XNSk9pcF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcBe-oA09pv8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVSBWO7a57Zw"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            self.texts = f.readlines()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True,\n",
        "                                  padding='max_length',\n",
        "                                  max_length=self.max_length,\n",
        "                                  return_tensors='pt') # Ensure PyTorch Tensor output\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "\n",
        "        # Assuming you want to use the input_ids as labels for language modeling\n",
        "\n",
        "        # Shift labels\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        labels[:-1] = input_ids[1:]  # Shift labels\n",
        "        return input_ids, labels  # Return both input_ids and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q42lwkv3nRk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "def train(model: Mistral,\n",
        "          train_data: DataLoader,\n",
        "          val_data: DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          epochs: int = 10,\n",
        "          device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "          clip_grad_norm: float = 1.0,\n",
        "          lr_scheduler=None):\n",
        "    \"\"\"Trains the Mistral model.\n",
        "\n",
        "    Args:\n",
        "        model: The Mistral model to train.\n",
        "        train_data: A DataLoader for the training dataset.\n",
        "        optimizer: The optimizer to use for training.\n",
        "        epochs: The number of training epochs.\n",
        "        device: The device to use for training (e.g., 'cuda' or 'cpu').\n",
        "        clip_grad_norm: The maximum norm of the gradients to clip.\n",
        "        lr_scheduler: An optional learning rate scheduler.\n",
        "    \"\"\"\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    print(\"Training...\")\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        total_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch in tqdm(train_data, leave=False):\n",
        "            input_ids, labels = batch\n",
        "\n",
        "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs, _ = model(input_ids)\n",
        "\n",
        "            # Calculate loss (use cross-entropy loss for language modeling)\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(outputs.view(-1, model.vocab_size), labels.view(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                lr_scheduler.step(loss.detach().item())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "\n",
        "        avg_loss = total_loss / len(train_data)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Average loss: {avg_loss:.4f} | Elapsed time: {elapsed_time:.2f}s\")\n",
        "\n",
        "\n",
        "        # Evaluation Phase\n",
        "        model.eval()\n",
        "        eval_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for step, batch in enumerate(val_data):\n",
        "                # Get input_ids and labels from the batch\n",
        "                input_ids, labels = batch\n",
        "                input_ids = input_ids.to(device)  # Send input_ids to the device\n",
        "                labels = labels.to(device)  # Send labels to the device\n",
        "\n",
        "                # Forward pass\n",
        "                outputs, _ = model(input_ids)\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = F.cross_entropy(outputs.view(-1, model.vocab_size), labels.view(-1), ignore_index=new_tokenizer.pad_token_id)\n",
        "                eval_loss += loss.item()\n",
        "        avg_eval_loss = eval_loss / len(val_data)\n",
        "        print(f\"Epoch: {epoch+1}, Evaluation Loss: {avg_eval_loss:.4f}\")\n",
        "    model_save_path = \"mistral.pt\"\n",
        "    torch.save(model.state_dict(), model_save_path)\n",
        "    print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY53sPJe31zW"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0Rj-hEm4kaX"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloaders\n",
        "train_dataset = TextDataset('/content/cleaned_data.txt',\n",
        "                            new_tokenizer,\n",
        "                            max_length=512)\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP7FOGzbIedk"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloaders\n",
        "val_dataset = TextDataset('/content/validation.txt',\n",
        "                            new_tokenizer,\n",
        "                            max_length=512)\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRWvTJjGGtso",
        "outputId": "10875e37-3f30-49a1-f677-0b912070626f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss: 0.6468 | Elapsed time: 384.01s\n",
            "Epoch: 1, Evaluation Loss: 6.6636\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "train(model ,\n",
        "      train_loader,\n",
        "      val_loader,\n",
        "      optimizer,\n",
        "      epochs=1,\n",
        "      device=device,\n",
        "      clip_grad_norm=1.0,\n",
        "      lr_scheduler=lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba7-V8u5_-U9"
      },
      "outputs": [],
      "source": [
        "max_length = 30\n",
        "num_return_sequences = 10\n",
        "\n",
        "\n",
        "tokens = new_tokenizer.encode(\"I'm a \")\n",
        "tokens = torch.tensor(tokens , dtype=torch.long)\n",
        "tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)\n",
        "\n",
        "x = tokens.to(device)\n",
        "\n",
        "while x.size(1) < max_length:\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "        logits = outputs[0] if isinstance(outputs, tuple) else outputs\n",
        "        logits = logits[:, -1, :]\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        topk_probs, topk_indices = torch.topk(probs, 50, dim=-1)\n",
        "\n",
        "        ix = torch.multinomial(topk_probs, 1)\n",
        "        xcol = torch.gather(topk_indices, -1, ix)\n",
        "        x = torch.cat((x, xcol), dim=1)\n",
        "\n",
        "# print the generated text\n",
        "for i in range(num_return_sequences):\n",
        "    tokens = x[i, :max_length].tolist()\n",
        "    decoded = new_tokenizer.decode(tokens, skip_special_tokens=True)\n",
        "    print(\">\", decoded)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
